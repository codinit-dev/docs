---
title: "Context Window Guide"
description: "How much the AI can remember at once"
---

## What is a Context Window?

A context window is how much text the AI can look at and remember at one time. Think of it like the AI's short-term memory.

<Note>
  **What are tokens?** Tokens are small pieces of text. About 4 letters = 1 token. So "hamburger" is 2 tokens: "ham" and "burger". When we say "128K tokens," that means the AI can remember about 96,000 words at once.
</Note>

<Tip>
  **Important**: Bigger context windows let the AI see more of your project, but they cost more money and take longer.
</Tip>

### Size Guide

| Size            | Tokens | About How Many Words | Good For                  |
| --------------- | ------ | ----------------- | ------------------------- |
| **Small**       | 8K-32K | 6,000-24,000      | One file, quick fixes |
| **Medium**      | 128K   | ~96,000           | Most projects      |
| **Large**       | 200K   | ~150,000          | Big projects         |
| **Extra Large** | 400K+  | ~300,000+         | Whole apps       |
| **Huge**     | 1M+    | ~750,000+         | Multiple projects    |

### Different AI Models

| AI Model                 | Context Window | Actually Works Well\* | Notes                          |
| --------------------- | -------------- | ------------------ | ------------------------------ |
| **Claude Sonnet 4.5** | 1M tokens      | ~500K tokens       | Best for big projects   |
| **GPT-5**             | 400K tokens    | ~300K tokens       | Has three different modes |
| **Gemini 2.5 Pro**    | 1M+ tokens     | ~600K tokens       | Great for reading documents        |
| **DeepSeek V3**       | 128K tokens    | ~100K tokens       | Good for most things         |
| **Qwen3 Coder**       | 256K tokens    | ~200K tokens       | Nice balance                   |

\*The AI works best up to this point. After that, it might start forgetting earlier parts of your chat.

### What Uses Up the Context Window

1. **Your messages** - Everything you and the AI say in the chat
2. **Your files** - Files the AI reads from your project
3. **Command results** - Output from commands that run
4. **System instructions** - CodinIT's background instructions (uses very little)

### How to Save Context Space

#### 1. Start fresh for new features

```mdx
/new - Start a new chat with empty context
```

Why this helps:

- You get the full context window
- No old, irrelevant messages
- AI focuses better

#### 2. Only include files you need

Instead of including everything:

- `@filename.ts` - Only mention files when necessary
- Use search instead of reading big files
- Reference specific parts, not whole files

#### 3. Turn on auto-compact

CodinIT can automatically shorten long conversations:

- Go to Settings → Features → Auto-compact
- Keeps important stuff
- Uses fewer tokens

## Warning Signs

### How to Tell You're Running Out of Space

| Warning Sign                  | What It Means                 | What to Do                              |
| ----------------------------- | ----------------------------- | ------------------------------------- |
| **"Context window exceeded"** | You hit the limit            | Start a new chat or turn on auto-compact |
| **Slow responses**          | AI is struggling | Include fewer files                 |
| **AI repeats itself**    | Context is too fragmented         | Start fresh             |
| **AI forgets recent changes**    | Too much context              | Use checkpoints      |

### Tips by Project Size

#### Small projects (less than 50 files)

- Any AI model works fine
- Include files freely
- Don't worry about optimization

#### Medium projects (50-500 files)

- Use AI with 128K+ context
- Only include files you're working on
- Start new chats between features

#### Large projects (500+ files)

- Use AI with 200K+ context
- Focus on one part at a time
- Search instead of reading many files
- Break work into smaller pieces

## Advanced Tips

### Use Plan/Act Mode Smartly

Use different AI models for different tasks:

- **Plan Mode**: Use cheaper AI for talking and planning
- **Act Mode**: Use better AI when writing code

Example:

```
Plan Mode: DeepSeek V3 (128K) - Cheap for planning
Act Mode: Claude Sonnet (1M) - Better for coding
```

### How CodinIT Saves Space

CodinIT can automatically remove less important text:

1. **Remove old messages**: Delete old parts of the conversation
2. **Keep relevant code**: Only keep code related to what you're doing now
3. **Keep summaries**: Keep the main ideas but remove details

### Counting Tokens

#### Quick math

- **1 token ≈ 3/4 of a word** (1,000 tokens = about 750 words)
- **1 token ≈ 4 letters**
- **100 lines of code ≈ 500-1000 tokens**

#### File sizes

| File Type      | Tokens per KB |
| -------------- | ------------- |
| **Code**       | ~250-400      |
| **JSON**       | ~300-500      |
| **Markdown**   | ~200-300      |
| **Plain text** | ~200-250      |

## Common Questions

### Q: Why does the AI get worse with long conversations?

**A:** The AI loses focus when there's too much to remember. It works best with 50-70% of its maximum.

### Q: Should I always use the biggest context window?

**A:** No. Bigger contexts cost more and can make the AI worse. Use what you need for your task.

### Q: How do I know how much context I'm using?

**A:** CodinIT shows you a meter. Watch it to see when you're getting close to the limit.

### Q: What happens if I go over the limit?

**A:** CodinIT will:

- Automatically shorten the conversation (if you turned that on)
- Show an error and tell you to start a new chat
- Remove old messages (with a warning)

## What to Use When

| What You're Doing                | Context Size | Which AI  |
| ----------------------- | ------------------- | ----------------- |
| **Quick fixes**         | 32K-128K            | DeepSeek V3       |
| **Building features** | 128K-200K           | Qwen3 Coder       |
| **Big changes**   | 400K+               | Claude Sonnet 4.5 |
| **Reviewing code**         | 200K-400K           | GPT-5             |
| **Writing docs**       | 128K                | Any cheap model  |