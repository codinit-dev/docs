---
title: "OpenRouter"
description: "Access multiple AI models through a unified API with OpenRouter."
---

OpenRouter provides access to models from multiple providers through a single API.

**Website:** [https://openrouter.ai/](https://openrouter.ai/)

## Getting an API Key

1. Go to [OpenRouter](https://openrouter.ai/) and sign in with Google or GitHub
2. Navigate to the [keys page](https://openrouter.ai/keys)
3. Copy your API key (or create a new one)

## Configuration

1. Click the settings icon (⚙️) in CodinIT
2. Select "OpenRouter" as the API Provider
3. Paste your API key
4. Choose your model

## Supported Models

CodinIT automatically fetches available models. Featured models include:

- **Claude Opus 4.5:** 200k context, maximum intelligence
- **Claude Sonnet 4.5:** 1M context, highest intelligence
- **GPT-5.2 Pro:** 400k context, latest GPT model
- **GPT-4o:** 128k context, reliable fallback
- **DeepSeek R1 (Free):** 163k context, free tier available

See [OpenRouter Models](https://openrouter.ai/models) for the complete list.

## Features

- **Message transforms:** Enable "Compress prompts and message chains to context size" to handle large prompts
- **Prompt caching:** Automatically passes caching to supported models
- **Gemini caching:** Manually enable "Enable Prompt Caching" for Gemini models

## Notes

- **Pricing:** Based on underlying model pricing. See [OpenRouter Models](https://openrouter.ai/models)