---
title: 'AI Model Providers - LLM Integration for Code Generation'
description: 'Connect CodinIT AI IDE with 19+ LLM providers including Claude, GPT-4, Gemini, DeepSeek for AI code generation, local inference, and specialized AI coding services.'
---

## Enterprise & research AI coding models

<CardGroup cols={2}>
  <Card title="Anthropic Claude AI" icon="/assets/ai-icons/anthropic.svg" href="/providers/anthropic">
    Claude 3.5 Sonnet LLM with advanced reasoning for AI code generation
  </Card>
  <Card title="OpenAI GPT models" icon="/assets/ai-icons/openai.svg" href="/providers/openai">
    GPT-4o and o1 series AI models for intelligent code completion
  </Card>
  <Card title="Google Gemini AI" icon="/assets/ai-icons/google.svg" href="/providers/google">
    Gemini 2.0 Flash LLM via GCP Vertex AI for AI-powered development
  </Card>
  <Card title="DeepSeek AI coding" icon="/assets/ai-icons/deepseek.svg" href="/providers/deepseek">
    DeepSeek V3 advanced reasoning models for cost-effective AI code generation
  </Card>
</CardGroup>

## Fast LLM inference & specialized AI coding

<CardGroup cols={3}>
  <Card title="Groq fast AI inference" icon="/assets/ai-icons/groq.svg" href="/providers/groq">
    Ultra-fast LPU inference for real-time AI code completion
  </Card>
  <Card title="Together AI models" icon="/assets/ai-icons/togetherai.svg" href="/providers/togetherai">
    50+ open-source LLMs for flexible AI code generation
  </Card>
  <Card title="Hyperbolic AI" icon="/assets/ai-icons/hyperbolic.svg" href="/providers/hyperbolic">
    Optimized open-source LLM inference for AI development
  </Card>
  <Card title="Perplexity AI search" icon="/assets/ai-icons/perplexity-color.svg" href="/providers/perplexity">
    AI coding with integrated web search for context-aware development
  </Card>
  <Card title="XAI Grok models" icon="/assets/ai-icons/xai.svg" href="/providers/xai-grok">
    Grok LLMs with large context windows for AI code generation
  </Card>
  <Card title="Fireworks AI" icon="/assets/ai-icons/fireworks.svg" href="/providers/fireworks">
    Fast LLM inference with 40+ AI models for code generation
  </Card>
</CardGroup>

## Open-source AI models & community LLMs

<CardGroup cols={3}>
  <Card title="Cohere AI models" icon="/assets/ai-icons/cohere.svg" href="/providers/cohere">
    Command R series LLMs for AI code generation and development
  </Card>
  <Card title="HuggingFace AI hub" icon="/assets/ai-icons/huggingface.svg" href="/providers/huggingface">
    Thousands of open-source community AI models for code generation
  </Card>
  <Card title="Mistral AI coding" icon="/assets/ai-icons/mistral.svg" href="/providers/mistral-ai">
    Mistral and Codestral LLMs specialized for AI-powered development
  </Card>
  <Card title="Moonshot AI" icon="/assets/ai-icons/moonshot.svg" href="/providers/moonshot">
    Kimi series LLMs with Chinese language support for AI coding
  </Card>
</CardGroup>

## Unified & Routing

<CardGroup cols={2}>
  <Card title="OpenRouter" icon="/assets/ai-icons/openrouter.svg" href="/providers/openrouter">
    Multiple models, unified API
  </Card>
  <Card title="OpenAI Compatible" icon="/assets/ai-icons/openai.svg" href="/providers/openai-like">
    Any OpenAI-compatible endpoint
  </Card>
</CardGroup>

## Cloud & Enterprise

<CardGroup cols={2}>
  <Card title="AWS Bedrock" icon="/assets/ai-icons/bedrock.svg" href="/providers/aws-bedrock">
    Enterprise AI via AWS
  </Card>
  <Card title="GitHub Models" icon="/assets/ai-icons/github.svg" href="/providers/github">
    Models through GitHub platform
  </Card>
</CardGroup>

## Local & Private

<CardGroup cols={2}>
  <Card title="Ollama" icon="/assets/ai-icons/ollama.svg" href="/providers/ollama">
    Run models locally with Ollama
  </Card>
  <Card title="LM Studio" icon="/assets/ai-icons/lmstudio.svg" href="/providers/lmstudio">
    Desktop app for local models
  </Card>
</CardGroup>

## Choosing a Provider

**Performance & Speed:**
- Ultra-fast: Groq, Together AI, Fireworks
- Best reasoning: Anthropic Claude, DeepSeek, OpenAI o1
- Balanced: OpenAI GPT-4, Google Gemini, Cohere

**Cost:**
- Free/Low-cost: Local models (Ollama, LM Studio), OpenRouter
- Budget-friendly: Together AI, HuggingFace, Hyperbolic
- Premium: Anthropic, OpenAI, Google

**Privacy:**
- Maximum privacy: Local models (Ollama, LM Studio)
- Enterprise-grade: AWS Bedrock, Anthropic
- Cloud security: OpenAI, Google, Cohere

**Capabilities:**
- Code generation: All providers, specialized: Cohere, Together AI
- Multimodal: Google Gemini, OpenAI GPT-4 Vision, Moonshot
- Long context: Claude (200K+), Gemini (1M+), GPT-4 (128K)
- Search integration: Perplexity
- Multilingual: Cohere, Google, Moonshot (Chinese)

## Quick Start

<Steps>
  <Step title="Choose Provider">Select based on needs: speed, cost, capabilities, or privacy</Step>
  <Step title="Get Credentials">Sign up and get API keys (cloud) or install software (local)</Step>
  <Step title="Configure CodinIT">Add credentials in CodinIT settings</Step>
  <Step title="Select Model">Choose from available models</Step>
  <Step title="Start Building">Begin using AI in your workflow</Step>
</Steps>

## Notes

- **Multi-provider:** Configure multiple providers and switch between them
- **API security:** Keys stored locally, never transmitted to CodinIT servers
- **Rate limits:** Each provider has different limits
- **Local vs Cloud:** Local offers privacy but requires hardware; cloud offers convenience and advanced features
