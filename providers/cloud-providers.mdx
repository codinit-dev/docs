---
title: 'AI Model Providers - LLM Integration for Code Generation'
description: 'Connect CodinIT AI IDE with 19+ LLM providers including Claude, GPT-4, Gemini, DeepSeek for AI code generation, local inference, and specialized AI coding services.'
---

## Enterprise & Research Models

<CardGroup cols={2}>
  <Card title="Anthropic" icon="/assets/ai-icons/anthropic.svg" href="/providers/anthropic">
    Claude models with advanced reasoning
  </Card>
  <Card title="OpenAI" icon="/assets/ai-icons/openai.svg" href="/providers/openai">
    GPT-5 and o-series models
  </Card>
  <Card title="Google" icon="/assets/ai-icons/google.svg" href="/providers/google">
    Gemini models via GCP Vertex AI
  </Card>
  <Card title="DeepSeek" icon="/assets/ai-icons/deepseek.svg" href="/providers/deepseek">
    Advanced reasoning models
  </Card>
</CardGroup>

## Fast Inference & Specialized

<CardGroup cols={3}>
  <Card title="Groq" icon="/assets/ai-icons/groq.svg" href="/providers/groq">
    Ultra-fast LPU inference
  </Card>
  <Card title="Together AI" icon="/assets/ai-icons/togetherai.svg" href="/providers/togetherai">
    50+ open-source models
  </Card>
  <Card title="Hyperbolic" icon="/assets/ai-icons/hyperbolic.svg" href="/providers/hyperbolic">
    Optimized open-source inference
  </Card>
  <Card title="Perplexity" icon="/assets/ai-icons/perplexity-color.svg" href="/providers/perplexity">
    AI with integrated web search
  </Card>
  <Card title="XAI Grok" icon="/assets/ai-icons/xai.svg" href="/providers/xai-grok">
    Grok models with large context
  </Card>
  <Card title="Fireworks" icon="/assets/ai-icons/fireworks.svg" href="/providers/fireworks">
    Fast inference, 40+ models
  </Card>
</CardGroup>

## Open Source & Community

<CardGroup cols={3}>
  <Card title="Cohere" icon="/assets/ai-icons/cohere.svg" href="/providers/cohere">
    Command R series models
  </Card>
  <Card title="HuggingFace" icon="/assets/ai-icons/huggingface.svg" href="/providers/huggingface">
    Thousands of community models
  </Card>
  <Card title="Mistral AI" icon="/assets/ai-icons/mistral.svg" href="/providers/mistral-ai">
    Mistral and Codestral models
  </Card>
  <Card title="Moonshot" icon="/assets/ai-icons/moonshot.svg" href="/providers/moonshot">
    Kimi series, Chinese language
  </Card>
</CardGroup>

## Unified & Routing

<CardGroup cols={2}>
  <Card title="OpenRouter" icon="/assets/ai-icons/openrouter.svg" href="/providers/openrouter">
    Multiple models, unified API
  </Card>
  <Card title="OpenAI Compatible" icon="/assets/ai-icons/openai.svg" href="/providers/openai-like">
    Any OpenAI-compatible endpoint
  </Card>
</CardGroup>

## Cloud & Enterprise

<CardGroup cols={2}>
  <Card title="AWS Bedrock" icon="/assets/ai-icons/bedrock.svg" href="/providers/aws-bedrock">
    Enterprise AI via AWS
  </Card>
  <Card title="GitHub Models" icon="/assets/ai-icons/github.svg" href="/providers/github">
    Models through GitHub platform
  </Card>
</CardGroup>

## Local & Private

<CardGroup cols={2}>
  <Card title="Ollama" icon="/assets/ai-icons/ollama.svg" href="/providers/ollama">
    Run models locally with Ollama
  </Card>
  <Card title="LM Studio" icon="/assets/ai-icons/lmstudio.svg" href="/providers/lmstudio">
    Desktop app for local models
  </Card>
</CardGroup>

## Choosing a Provider

**Performance & Speed:**
- Ultra-fast: Groq, Together AI, Fireworks
- Best reasoning: Anthropic Claude, DeepSeek, OpenAI o1
- Balanced: OpenAI GPT-4, Google Gemini, Cohere

**Cost:**
- Free/Low-cost: Local models (Ollama, LM Studio), OpenRouter
- Budget-friendly: Together AI, HuggingFace, Hyperbolic
- Premium: Anthropic, OpenAI, Google

**Privacy:**
- Maximum privacy: Local models (Ollama, LM Studio)
- Enterprise-grade: AWS Bedrock, Anthropic
- Cloud security: OpenAI, Google, Cohere

**Capabilities:**
- Code generation: All providers, specialized: Cohere, Together AI
- Multimodal: Google Gemini, OpenAI GPT-4 Vision, Moonshot
- Long context: Claude (200K+), Gemini (1M+), GPT-4 (128K)
- Search integration: Perplexity
- Multilingual: Cohere, Google, Moonshot (Chinese)

## Quick Start

<Steps>
  <Step title="Choose Provider">Select based on needs: speed, cost, capabilities, or privacy</Step>
  <Step title="Get Credentials">Sign up and get API keys (cloud) or install software (local)</Step>
  <Step title="Configure CodinIT">Add credentials in CodinIT settings</Step>
  <Step title="Select Model">Choose from available models</Step>
  <Step title="Start Building">Begin using AI in your workflow</Step>
</Steps>

## Notes

- **Multi-provider:** Configure multiple providers and switch between them
- **API security:** Keys stored locally, never transmitted to CodinIT servers
- **Rate limits:** Each provider has different limits
- **Local vs Cloud:** Local offers privacy but requires hardware; cloud offers convenience and advanced features
